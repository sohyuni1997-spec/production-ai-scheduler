import streamlit as st
import pandas as pd
from supabase import create_client, Client
import requests
from datetime import datetime, timedelta
import re

# 1. Supabase ì—°ê²° ì„¤ì •
URL = "https://suaajrdahixouinbfcfo.supabase.co"
KEY = "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6InN1YWFqcmRhaGl4b3VpbmJmY2ZvIiwicm9sZSI6ImFub24iLCJpYXQiOjE3NjYzMTk4NzAsImV4cCI6MjA4MTg5NTg3MH0.Ic4izQY-ihIw75jKh9iJicZvuZ4gCRs4OH3rCGyo0Zk"
supabase: Client = create_client(URL, KEY)

# CAPA ì •ë³´
CAPA_INFO = {
    "ì¡°ë¦½1": 3000,
    "ì¡°ë¦½2": 2500,
    "ì¡°ë¦½3": 2000
}

# ë‚ ì§œ íŒŒì‹± í•¨ìˆ˜
def parse_date(date_str):
    """9/17 -> 2025-09-17 ë³€í™˜"""
    try:
        if '/' in date_str:
            parts = date_str.split('/')
            month = parts[0].zfill(2)
            day = parts[1].zfill(2)
            return f"2025-{month}-{day}"
        return date_str
    except:
        return None

# ë‚ ì§œ ë²”ìœ„ ê³„ì‚°
def get_date_range(target_date, days_before=14, days_after=7):
    """íŠ¹ì • ë‚ ì§œ ê¸°ì¤€ ì „í›„ ë²”ìœ„ ê³„ì‚°"""
    try:
        dt = datetime.strptime(target_date, '%Y-%m-%d')
        start = (dt - timedelta(days=days_before)).strftime('%Y-%m-%d')
        end = (dt + timedelta(days=days_after)).strftime('%Y-%m-%d')
        return start, end
    except:
        return None, None

# DB ì¡°íšŒ í•¨ìˆ˜ (ë²„ì „ë³„)
def fetch_production_data(target_date, version='2ì°¨'):
    """
    íŠ¹ì • ë‚ ì§œ í¬í•¨ ì „í›„ 2ì£¼ ë°ì´í„° ì¡°íšŒ
    version: '0ì°¨', '1ì°¨', '2ì°¨'
    """
    start_date, end_date = get_date_range(target_date)
    
    if not start_date:
        return None
    
    response = supabase.table("pattern_learning")\
        .select("*")\
        .eq("version", version)\
        .gte("plan_date", start_date)\
        .lte("plan_date", end_date)\
        .order("plan_date", desc=False)\
        .execute()
    
    return pd.DataFrame(response.data) if response.data else None

# 0ì°¨ vs 2ì°¨ ë¹„êµ í•¨ìˆ˜
def compare_versions(df_0, df_2):
    """0ì°¨(ì›ë³¸)ì™€ 2ì°¨(ì‹¤ì œ) ë¹„êµ"""
    if df_0 is None or df_2 is None:
        return None
    
    # ê³µí†µ í‚¤ë¡œ ë³‘í•© (plan_date, line, product_name)
    merged = pd.merge(
        df_0[['plan_date', 'line', 'product_name', 'category', 'qty_0ì°¨']],
        df_2[['plan_date', 'line', 'product_name', 'category', 'qty_2ì°¨', 'production_date', 'worker_memo']],
        on=['plan_date', 'line', 'product_name', 'category'],
        how='outer',
        suffixes=('_0ì°¨', '_2ì°¨')
    )
    
    # ë³€ê²½ì‚¬í•­ ê³„ì‚°
    merged['qty_diff'] = merged['qty_2ì°¨'].fillna(0) - merged['qty_0ì°¨'].fillna(0)
    merged['changed'] = merged['qty_diff'] != 0
    
    return merged

# ë°ì´í„° ë¶„ì„ í•¨ìˆ˜
def analyze_data(df, version='2ì°¨'):
    """CAPA ì‚¬ìš©ë¥ , ìš”ì¼ë³„ ë¶„í¬ ë“± ë¶„ì„"""
    analysis = {'version': version}
    
    # ë‚ ì§œë¥¼ datetimeìœ¼ë¡œ ë³€í™˜
    df['plan_date_dt'] = pd.to_datetime(df['plan_date'])
    df['weekday'] = df['plan_date_dt'].dt.day_name()
    df['weekday_kr'] = df['plan_date_dt'].dt.strftime('%A').map({
        'Monday': 'ì›”', 'Tuesday': 'í™”', 'Wednesday': 'ìˆ˜',
        'Thursday': 'ëª©', 'Friday': 'ê¸ˆ', 'Saturday': 'í† ', 'Sunday': 'ì¼'
    })
    
    # ìˆ˜ëŸ‰ ì»¬ëŸ¼ ì„ íƒ (ë²„ì „ì— ë”°ë¼)
    qty_col = f'qty_{version}'
    
    # ë¼ì¸ë³„ ì¼ì¼ ìƒì‚°ëŸ‰ ê³„ì‚°
    for line in ["ì¡°ë¦½1", "ì¡°ë¦½2", "ì¡°ë¦½3"]:
        line_data = df[df['line'] == line]
        daily_sum = line_data.groupby('plan_date')[qty_col].sum()
        
        max_capa = CAPA_INFO[line]
        target_capa = max_capa * 0.9
        
        analysis[line] = {
            'max_capa': max_capa,
            'target_90': int(target_capa),
            'daily_production': daily_sum.to_dict(),
            'over_capacity_days': daily_sum[daily_sum > target_capa].to_dict()
        }
    
    # BERGSTROM ìƒì‚°ì¼ í™•ì¸
    bergstrom_data = df[df['product_name'].str.contains('BERGSTROM', case=False, na=False)]
    bergstrom_days = bergstrom_data.groupby('plan_date')[qty_col].sum().to_dict()
    
    # ì¡°ë¦½2 ìš”ì¼ë³„ FAN/FLANGE ì²´í¬
    line2_data = df[df['line'] == 'ì¡°ë¦½2'].copy()
    
    # FAN: ì›”/ìˆ˜/ê¸ˆë§Œ ê°€ëŠ¥
    fan_data = line2_data[line2_data['category'] == 'FAN']
    fan_wrong = fan_data[~fan_data['weekday_kr'].isin(['ì›”', 'ìˆ˜', 'ê¸ˆ'])]
    
    # FLANGE: í™”/ëª©ë§Œ ê°€ëŠ¥
    flange_data = line2_data[line2_data['category'] == 'FLANGE']
    flange_wrong = flange_data[~flange_data['weekday_kr'].isin(['í™”', 'ëª©'])]
    
    analysis['bergstrom_days'] = bergstrom_days
    analysis['fan_violations'] = fan_wrong[['plan_date', 'product_name', qty_col, 'weekday_kr']].to_dict('records')
    analysis['flange_violations'] = flange_wrong[['plan_date', 'product_name', qty_col, 'weekday_kr']].to_dict('records')
    
    # ì¡°ë¦½2 ì¼ì¼ í’ˆëª© ìˆ˜ ì²´í¬
    line2_daily_products = line2_data.groupby('plan_date')['product_name'].nunique()
    analysis['line2_over_5products'] = line2_daily_products[line2_daily_products > 5].to_dict()
    
    return analysis

# AI ë¶„ì„ í•¨ìˆ˜
def ask_professional_scheduler(question, df, analysis, comparison_df=None):
    api_url = "https://ai.potens.ai/api/chat"
    api_key = "qD2gfuVAkMJexDAcFb5GnEb1SZksTs7o"
    headers = {"Content-Type": "application/json", "Authorization": f"Bearer {api_key}"}
    
    # ë²„ì „ ì •ë³´
    version = analysis.get('version', '2ì°¨')
    qty_col = f'qty_{version}'
    
    # ë°ì´í„° ìš”ì•½
    df_summary = df[['plan_date', 'line', 'product_name', 'category', 'plt', qty_col, 'worker_memo']].to_string(index=False, max_rows=100)
    
    # 0ì°¨ vs 2ì°¨ ë³€ê²½ì‚¬í•­ ìš”ì•½
    change_summary = ""
    if comparison_df is not None:
        changed = comparison_df[comparison_df['changed'] == True]
        if not changed.empty:
            change_summary = f"\n\n[0ì°¨ ëŒ€ë¹„ 2ì°¨ ë³€ê²½ì‚¬í•­]\nì´ {len(changed)}ê±´ ë³€ê²½\n"
            change_summary += changed[['plan_date', 'line', 'product_name', 'qty_0ì°¨', 'qty_2ì°¨', 'qty_diff', 'worker_memo']].to_string(index=False, max_rows=20)
    
    # ìœ„ë°˜ì‚¬í•­ ìš”ì•½
    violations_summary = ""
    if analysis['fan_violations']:
        violations_summary += f"\nâš ï¸ FAN ìš”ì¼ê·œì¹™ ìœ„ë°˜: {len(analysis['fan_violations'])}ê±´"
        for v in analysis['fan_violations'][:3]:
            violations_summary += f"\n  - {v['plan_date']} ({v['weekday_kr']}): {v['product_name']} {v.get(qty_col, 0)}ê°œ"
    
    if analysis['flange_violations']:
        violations_summary += f"\nâš ï¸ FLANGE ìš”ì¼ê·œì¹™ ìœ„ë°˜: {len(analysis['flange_violations'])}ê±´"
        for v in analysis['flange_violations'][:3]:
            violations_summary += f"\n  - {v['plan_date']} ({v['weekday_kr']}): {v['product_name']} {v.get(qty_col, 0)}ê°œ"
    
    if analysis['line2_over_5products']:
        violations_summary += f"\nâš ï¸ ì¡°ë¦½2 5í’ˆëª© ì´ˆê³¼ì¼: {list(analysis['line2_over_5products'].keys())}"
    
    system_rules = f"""
ë‹¹ì‹ ì€ ìë™ì°¨ ë¶€í’ˆ ì¡°ë¦½ë¼ì¸ì˜ 'ìˆ˜ì„ ìƒì‚° ìŠ¤ì¼€ì¤„ëŸ¬'ì…ë‹ˆë‹¤.

[ë°ì´í„° ë²„ì „ ì •ë³´]
í˜„ì¬ ë¶„ì„ ëŒ€ìƒ: **{version}** (ì‹¤ì œ ì¡°ì •ë³¸)
- 0ì°¨: ì›ë³¸ ë‚©ê¸° ë°ì´í„° (ìë™ë¶„ë°° ì „)
- 1ì°¨: 10ê°€ì§€ ê·œì¹™ ì ìš©í•œ ìë™ë¶„ë°° ê²°ê³¼ (íŒ€ì› ê°œë°œ ì˜ˆì •)
- 2ì°¨: ê¸´ê¸‰ìƒí™© ë°˜ì˜í•œ ì‹¤ì œ ìƒì‚° ê³„íš (í˜„ì¬)

[í˜„ì¬ CAPA ì •ë³´ ë° ì‚¬ìš© í˜„í™©]
â€¢ ì¡°ë¦½1: ìµœëŒ€ {CAPA_INFO['ì¡°ë¦½1']}ê°œ/ì¼ (ëª©í‘œ 90% = {analysis['ì¡°ë¦½1']['target_90']}ê°œ)
  â†’ ì´ˆê³¼ ë°œìƒì¼: {list(analysis['ì¡°ë¦½1']['over_capacity_days'].keys()) if analysis['ì¡°ë¦½1']['over_capacity_days'] else 'ì—†ìŒ'}

â€¢ ì¡°ë¦½2: ìµœëŒ€ {CAPA_INFO['ì¡°ë¦½2']}ê°œ/ì¼ (ëª©í‘œ 90% = {analysis['ì¡°ë¦½2']['target_90']}ê°œ)
  â†’ ì´ˆê³¼ ë°œìƒì¼: {list(analysis['ì¡°ë¦½2']['over_capacity_days'].keys()) if analysis['ì¡°ë¦½2']['over_capacity_days'] else 'ì—†ìŒ'}

â€¢ ì¡°ë¦½3: ìµœëŒ€ {CAPA_INFO['ì¡°ë¦½3']}ê°œ/ì¼ (ëª©í‘œ 90% = {analysis['ì¡°ë¦½3']['target_90']}ê°œ)
  â†’ ì´ˆê³¼ ë°œìƒì¼: {list(analysis['ì¡°ë¦½3']['over_capacity_days'].keys()) if analysis['ì¡°ë¦½3']['over_capacity_days'] else 'ì—†ìŒ'}

[íŠ¹ì´ì‚¬í•­ ë° ìœ„ë°˜ì‚¬í•­]
â€¢ BERGSTROM ìƒì‚° ê³„íš: {analysis['bergstrom_days']}
  (âš ï¸ í•´ë‹¹ì¼ ì¡°ë¦½1 CAPAëŠ” 2,600ê°œë¡œ ì œí•œ, í•˜ë£¨ ìµœëŒ€ 525ê°œë§Œ ìƒì‚° ê°€ëŠ¥)
{violations_summary}

{change_summary}

[ìë™ë¶„ë°° í•µì‹¬ ê·œì¹™ - 1ì°¨ ìƒì„± ì‹œ ì ìš© ì˜ˆì •]
1. **CAPA ì œì•½**: ê° ì¡°ë¦½ ë¼ì¸ 1ì¼ ìƒì‚°ëŸ‰ì€ ìµœëŒ€ CAPAì˜ 90% ì´ë‚´
2. **PLT ë°°ìˆ˜**: ë‚©ê¸°ì¼(plan_date) í¬í•¨ ì´ì „ ë‚ ì§œì— PLT ë°°ìˆ˜ë¡œ ë¶„ë°°
3. **íœ´ë¬´ ì œì•½**: worker_memoì— 'íœ´ë¬´' ìˆìœ¼ë©´ ìƒì‚° ë¶ˆê°€
4. **ì¡°ë¦½2 ì¹´í…Œê³ ë¦¬ë³„ ìš”ì¼ ì œì•½**:
   - **FAN**: ì›”/ìˆ˜/ê¸ˆë§Œ ìƒì‚° ê°€ëŠ¥
   - **FLANGE**: í™”/ëª©ë§Œ ìƒì‚° ê°€ëŠ¥
   - **MOTOR**: ìš”ì¼ ë¬´ê´€
5. **ê· ë“± ë¶„ë°°**: í•˜ë£¨ì— 0ê°œ ë°°ë¶„ ê¸ˆì§€, ìµœëŒ€í•œ ê³ ë¥´ê²Œ ë¶„í¬
6. **2ì£¼ ì œì•½**: ë‚©ê¸°ì¼ ê¸°ì¤€ 2ì£¼ ì „ë¶€í„° ë°°ë¶„ ì‹œì‘
7. **ì¡°ë¦½2 í’ˆëª© ì œí•œ**: í•˜ë£¨ ìµœëŒ€ 5í’ˆëª© ìƒì‚°
8. **0 ë°°ë¶„ ê¸ˆì§€**: ì–´ë–¤ ë‚ ë„ 0ê°œê°€ ë°°ë¶„ë˜ì§€ ì•Šë„ë¡ ì¡°ì •
9. **ê³ ë¥¸ ë¶„í¬**: ìµœëŒ€í•œ ê· ë“±í•˜ê²Œ ìˆ˜ëŸ‰ ë¶„ì‚°
10. **ë¬¼ë¥˜ ì œì•½**: ë‚©ê¸°ì¼ 2ì£¼ ì „ë¶€í„°ë§Œ ìƒì‚° ê°€ëŠ¥

[ì˜ˆì™¸ìƒí™© ëŒ€ì‘ ê·œì¹™]
11. **ì¡°ë¦½1 Buffer**: ìƒ˜í”Œìš”ì²­/ê³µì •ê°ì‚¬ ëŒ€ë¹„ ì—¬ìœ  20% ê¶Œì¥
12. **BERGSTROM íŠ¹ìˆ˜ ì²˜ë¦¬**: ì‹œê°„ë‹¹ 90ê°œ, í•˜ë£¨ ìµœëŒ€ 525ê°œ, í•´ë‹¹ì¼ ì¡°ë¦½1 CAPA 2,600ê°œ
13. **ìˆ˜ë°€ ë¼ì¸ í™•ì¥**: 'T6 (P703) ìˆ˜ë°€(U725)' ì¡°ë¦½1 ì´ˆê³¼ ì‹œ 1/2/3 ë¼ì¸ ëª¨ë‘ í™œìš©
14. **ì›”ë§ ìœ ì—°ì„±**: ì¡°ë¦½2 ìš”ì¼ê·œì¹™ì€ ì›”ë§(25ì¼ ì´í›„) ìœ ì—° ì ìš© ê°€ëŠ¥
15. **CAPA ë³€ë™**: ê¸´ê¸‰ ìƒí™© ì‹œ CAPA ì¡°ì • ê°€ëŠ¥

[í˜„ì¬ ìƒì‚° ê³„íš ë°ì´í„° - {version}]
{df_summary}

[í•„ìˆ˜ ì¶œë ¥ í˜•ì‹]
ë°˜ë“œì‹œ ì•„ë˜ í˜•ì‹ìœ¼ë¡œ **3ê°€ì§€ ëŒ€ì•ˆ**ì„ ì œì‹œí•˜ì‹­ì‹œì˜¤:

---
## ğŸ¯ ëŒ€ì•ˆ 1: [ëŒ€ì•ˆëª…]

### ğŸ“Œ êµ¬ì²´ì  ì¡°ì¹˜ì‚¬í•­
- **[ë‚ ì§œ]** [í’ˆëª©ëª…] (category: [FAN/FLANGE/MOTOR]) [ê¸°ì¡´ìˆ˜ëŸ‰]ê°œ â†’ [ë³€ê²½ìˆ˜ëŸ‰]ê°œ ([ê¸°ì¡´ë¼ì¸] â†’ [ë³€ê²½ë¼ì¸])
  *ì´ìœ : [êµ¬ì²´ì  ì‚¬ìœ ]*

### âœ… ì¥ì 
1. 
2. 

### âš ï¸ ë‹¨ì 
1. 
2. 

### ğŸ”® ë°œìƒ ê°€ëŠ¥ ìƒí™©
1. 
2. 

---
## ğŸ¯ ëŒ€ì•ˆ 2: [ëŒ€ì•ˆëª…]
(ë™ì¼ í˜•ì‹)

---
## ğŸ¯ ëŒ€ì•ˆ 3: [ëŒ€ì•ˆëª…]
(ë™ì¼ í˜•ì‹)
"""
    
    payload = {"prompt": f"{system_rules}\n\n[ì‚¬ìš©ì ê¸´ê¸‰ ìš”ì²­]\n{question}"}
    
    try:
        response = requests.post(api_url, headers=headers, json=payload, timeout=90)
        if response.status_code == 200:
            return response.json().get('message', 'ì‘ë‹µ í˜•ì‹ ì˜¤ë¥˜')
        else:
            return f"âŒ API ì˜¤ë¥˜ (Status {response.status_code}): {response.text}"
    except Exception as e:
        return f"âŒ ìš”ì²­ ì‹¤íŒ¨: {str(e)}"

# --- UI êµ¬ì„± ---
st.set_page_config(page_title="ìˆ˜ì„ ìŠ¤ì¼€ì¤„ëŸ¬ AI ê´€ì œ ì„¼í„°", layout="wide")
st.title("ğŸ‘¨â€âœˆï¸ ìˆ˜ì„ ìŠ¤ì¼€ì¤„ëŸ¬ AI í†µí•© ì œì–´ (Real-DB)")

# ì„¸ì…˜ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state.messages = []

# ìƒë‹¨ ë²„ì „ ì„ íƒ
version_option = st.radio(
    "ğŸ“‚ ë¶„ì„ ëŒ€ìƒ ì„ íƒ",
    options=['2ì°¨ (ì‹¤ì œ ì¡°ì •ë³¸)', '0ì°¨ vs 2ì°¨ ë¹„êµ'],
    horizontal=True,
    help="1ì°¨(ìë™ë¶„ë°°)ëŠ” íŒ€ì› ê°œë°œ ì™„ë£Œ í›„ ì¶”ê°€ ì˜ˆì •"
)

# 2ë‹¨ ë ˆì´ì•„ì›ƒ
left_col, right_col = st.columns([1, 1.2])

with left_col:
    st.subheader("ğŸ’¬ AI ìƒë‹´ ì°½êµ¬")
    
    # ëŒ€í™” íˆìŠ¤í† ë¦¬ í‘œì‹œ
    for msg in st.session_state.messages:
        with st.chat_message(msg["role"]):
            st.markdown(msg["content"])

    # ì‚¬ìš©ì ì…ë ¥
    if prompt := st.chat_input("ì˜ˆ: 9/17 ì¡°ë¦½1 ê³µì •ê°ì‚¬ ì´ìŠˆ ë¶„ì„í•˜ê³  ëŒ€ì•ˆ ë¦¬ìŠ¤íŠ¸ ë½‘ì•„ì¤˜."):
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        try:
            # ë‚ ì§œ ì¶”ì¶œ
            date_match = re.search(r'(\d{1,2})/(\d{1,2})', prompt)
            if not date_match:
                st.error("âŒ ë‚ ì§œ í˜•ì‹ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (ì˜ˆ: 9/17)")
                st.stop()
            
            date_val = f"{date_match.group(1)}/{date_match.group(2)}"
            formatted_date = parse_date(date_val)
            
            # ë²„ì „ë³„ ë°ì´í„° ì¡°íšŒ
            if 'ë¹„êµ' in version_option:
                # 0ì°¨ì™€ 2ì°¨ ëª¨ë‘ ì¡°íšŒ
                with st.spinner(f"ğŸ“¡ {date_val} ê¸°ì¤€ 0ì°¨/2ì°¨ ë°ì´í„° ì¡°íšŒ ì¤‘..."):
                    df_0 = fetch_production_data(formatted_date, version='0ì°¨')
                    df_2 = fetch_production_data(formatted_date, version='2ì°¨')
                
                if df_0 is None or df_2 is None:
                    st.warning(f"âš ï¸ {date_val}ì— í•´ë‹¹í•˜ëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                    st.stop()
                
                # ë¹„êµ ë°ì´í„° ìƒì„±
                comparison_df = compare_versions(df_0, df_2)
                
                # 2ì°¨ ê¸°ì¤€ìœ¼ë¡œ ë¶„ì„
                with st.spinner("ğŸ” ë³€ê²½ì‚¬í•­ ë¶„ì„ ì¤‘..."):
                    analysis = analyze_data(df_2, version='2ì°¨')
                
                # AI ë¶„ì„ (ë¹„êµ ì •ë³´ í¬í•¨)
                with st.chat_message("assistant"):
                    with st.spinner("ğŸ§  ìˆ˜ì„ ìŠ¤ì¼€ì¤„ëŸ¬ê°€ ëŒ€ì•ˆì„ ìˆ˜ë¦½ ì¤‘ì…ë‹ˆë‹¤..."):
                        answer = ask_professional_scheduler(prompt, df_2, analysis, comparison_df)
                        st.markdown(answer)
                        st.session_state.messages.append({"role": "assistant", "content": answer})
                
                # ì˜¤ë¥¸ìª½ì— ë¹„êµ ë°ì´í„° í‘œì‹œ
                with right_col:
                    st.subheader(f"ğŸ“Š 0ì°¨ vs 2ì°¨ ë¹„êµ ({date_val})")
                    
                    # ë³€ê²½ì‚¬í•­ë§Œ í•„í„°ë§
                    changed_only = st.checkbox("ë³€ê²½ì‚¬í•­ë§Œ ë³´ê¸°", value=True)
                    
                    if changed_only:
                        display_df = comparison_df[comparison_df['changed'] == True]
                    else:
                        display_df = comparison_df
                    
                    # ìƒ‰ìƒ í‘œì‹œ
                    def highlight_changes(row):
                        if row['qty_diff'] > 0:
                            return ['background-color: #d4edda'] * len(row)  # ì¦ê°€ (ë…¹ìƒ‰)
                        elif row['qty_diff'] < 0:
                            return ['background-color: #f8d7da'] * len(row)  # ê°ì†Œ (ë¹¨ê°•)
                        return [''] * len(row)
                    
                    st.dataframe(
                        display_df[['plan_date', 'line', 'product_name', 'category', 'qty_0ì°¨', 'qty_2ì°¨', 'qty_diff', 'worker_memo']].style.apply(highlight_changes, axis=1),
                        use_container_width=True,
                        height=400
                    )
                    
                    # í†µê³„
                    st.metric("ì´ ë³€ê²½ ê±´ìˆ˜", len(comparison_df[comparison_df['changed'] == True]))
                    col1, col2 = st.columns(2)
                    with col1:
                        st.metric("ì¦ê°€", len(comparison_df[comparison_df['qty_diff'] > 0]))
                    with col2:
                        st.metric("ê°ì†Œ", len(comparison_df[comparison_df['qty_diff'] < 0]))
            
            else:
                # 2ì°¨ë§Œ ì¡°íšŒ
                with st.spinner(f"ğŸ“¡ {date_val} ê¸°ì¤€ 2ì°¨ ë°ì´í„° ì¡°íšŒ ì¤‘..."):
                    df = fetch_production_data(formatted_date, version='2ì°¨')
                
                if df is None or df.empty:
                    st.warning(f"âš ï¸ {date_val}ì— í•´ë‹¹í•˜ëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                    st.stop()
                
                # ë°ì´í„° ë¶„ì„
                with st.spinner("ğŸ” CAPA ë° ìš”ì¼ê·œì¹™ ìœ„ë°˜ ê²€ì‚¬ ì¤‘..."):
                    analysis = analyze_data(df, version='2ì°¨')
                
                # AI ë¶„ì„
                with st.chat_message("assistant"):
                    with st.spinner("ğŸ§  ìˆ˜ì„ ìŠ¤ì¼€ì¤„ëŸ¬ê°€ ëŒ€ì•ˆì„ ìˆ˜ë¦½ ì¤‘ì…ë‹ˆë‹¤..."):
                        answer = ask_professional_scheduler(prompt, df, analysis)
                        st.markdown(answer)
                        st.session_state.messages.append({"role": "assistant", "content": answer})
                
                # ì˜¤ë¥¸ìª½ì— ë°ì´í„° í‘œì‹œ
                with right_col:
                    st.subheader(f"ğŸ“Š {date_val} ì „í›„ 2ì£¼ ë°ì´í„° (2ì°¨)")
                    
                    tab1, tab2, tab3 = st.tabs(["ğŸ“‹ ì „ì²´ ë°ì´í„°", "âš ï¸ ìœ„ë°˜ì‚¬í•­", "ğŸ“ˆ CAPA í˜„í™©"])
                    
                    with tab1:
                        col1, col2 = st.columns(2)
                        with col1:
                            filter_line = st.multiselect(
                                "ë¼ì¸ í•„í„°",
                                options=df['line'].unique(),
                                default=df['line'].unique()
                            )
                        with col2:
                            filter_category = st.multiselect(
                                "ì¹´í…Œê³ ë¦¬ í•„í„°",
                                options=df['category'].dropna().unique(),
                                default=df['category'].dropna().unique()
                            )
                        
                        filtered_df = df[
                            (df['line'].isin(filter_line)) & 
                            (df['category'].isin(filter_category))
                        ]
                        
                        st.dataframe(
                            filtered_df[['plan_date', 'line', 'product_name', 'category', 'plt', 'qty_2ì°¨', 'production_date', 'worker_memo']],
                            use_container_width=True,
                            height=400
                        )
                    
                    with tab2:
                        st.subheader("ğŸš¨ ìš”ì¼ê·œì¹™ ìœ„ë°˜")
                        
                        if analysis['fan_violations']:
                            st.error(f"**FAN ìœ„ë°˜**: {len(analysis['fan_violations'])}ê±´")
                            for v in analysis['fan_violations']:
                                st.write(f"- {v['plan_date']} ({v['weekday_kr']}): {v['product_name']} {v.get('qty_2ì°¨', 0)}ê°œ")
                        else:
                            st.success("âœ… FAN ìš”ì¼ê·œì¹™ ì¤€ìˆ˜")
                        
                        st.divider()
                        
                        if analysis['flange_violations']:
                            st.error(f"**FLANGE ìœ„ë°˜**: {len(analysis['flange_violations'])}ê±´")
                            for v in analysis['flange_violations']:
                                st.write(f"- {v['plan_date']} ({v['weekday_kr']}): {v['product_name']} {v.get('qty_2ì°¨', 0)}ê°œ")
                        else:
                            st.success("âœ… FLANGE ìš”ì¼ê·œì¹™ ì¤€ìˆ˜")
                        
                        st.divider()
                        
                        if analysis['line2_over_5products']:
                            st.warning(f"**ì¡°ë¦½2 5í’ˆëª© ì´ˆê³¼**: {len(analysis['line2_over_5products'])}ì¼")
                            for date, count in analysis['line2_over_5products'].items():
                                st.write(f"- {date}: {count}í’ˆëª©")
                        else:
                            st.success("âœ… ì¡°ë¦½2 í’ˆëª© ìˆ˜ ì¤€ìˆ˜")
                    
                    with tab3:
                        st.subheader("ğŸ“Š ë¼ì¸ë³„ CAPA ì‚¬ìš©ë¥ ")
                        
                        for line in ["ì¡°ë¦½1", "ì¡°ë¦½2", "ì¡°ë¦½3"]:
                            info = analysis[line]
                            st.write(f"**{line}**")
                            st.write(f"ìµœëŒ€: {info['max_capa']}ê°œ/ì¼ | ëª©í‘œ(90%): {info['target_90']}ê°œ/ì¼")
                            
                            if info['over_capacity_days']:
                                st.error(f"âš ï¸ ì´ˆê³¼ ë°œìƒì¼:")
                                for date, qty in info['over_capacity_days'].items():
                                    over_percent = (qty / info['max_capa']) * 100
                                    st.write(f"  - {date}: {int(qty)}ê°œ ({over_percent:.1f}%)")
                            else:
                                st.success("âœ… ëª¨ë“  ë‚ ì§œ ì •ìƒ ë²”ìœ„")
                            
                            st.divider()
                        
                        if analysis['bergstrom_days']:
                            st.warning("âš ï¸ BERGSTROM ìƒì‚°ì¼")
                            for date, qty in analysis['bergstrom_days'].items():
                                st.write(f"- {date}: {int(qty)}ê°œ")
        
        except Exception as e:
            st.error(f"âŒ ì‹œìŠ¤í…œ ì˜¤ë¥˜: {str(e)}")
            import traceback
            with st.expander("ìƒì„¸ ì˜¤ë¥˜ ë¡œê·¸"):
                st.code(traceback.format_exc())

# ì‚¬ì´ë“œë°”
with st.sidebar:
    st.header("ğŸ“– ì‚¬ìš© ê°€ì´ë“œ")
    
    st.info("""
    ### ğŸ“‚ ë°ì´í„° ë²„ì „
    - **0ì°¨**: ì›ë³¸ ë‚©ê¸° ë°ì´í„°
    - **1ì°¨**: ìë™ë¶„ë°° (ê°œë°œ ì˜ˆì • ğŸ”¨)
    - **2ì°¨**: ì‹¤ì œ ì¡°ì •ë³¸ âœ…
    """)
    
    st.markdown("""
    ### ğŸ’¬ ì§ˆë¬¸ ì˜ˆì‹œ
    ```
    9/17 ì¡°ë¦½1 ê³µì •ê°ì‚¬ë¡œ ìƒì‚° ë¶ˆê°€
    ```
    ```
    10/5 BERGSTROM ê¸´ê¸‰ ì¦ê°€
    ```
    
    ### ğŸ¯ ì£¼ìš” ê¸°ëŠ¥
    - âœ… 0ì°¨ vs 2ì°¨ ë³€ê²½ì‚¬í•­ ë¹„êµ
    - âœ… CAPA 90% ì´ˆê³¼ ê°ì§€
    - âœ… FAN/FLANGE ìš”ì¼ ìœ„ë°˜ ì²´í¬
    - âœ… 3ê°€ì§€ ëŒ€ì•ˆ + ì¥ë‹¨ì  ë¶„ì„
    
    ### ğŸ“‹ ì¹´í…Œê³ ë¦¬ ìš”ì¼ ê·œì¹™
    - **FAN**: ì›”/ìˆ˜/ê¸ˆ
    - **FLANGE**: í™”/ëª©
    - **MOTOR**: ë¬´ê´€
    """)
    
    st.divider()
    st.caption("Powered by Potens.AI")
